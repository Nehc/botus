{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPT-Chatbot.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNG5QyZhh/3whKsVa25jmyE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLKzsJ9fRdWo","executionInfo":{"status":"ok","timestamp":1655551846410,"user_tz":-180,"elapsed":22,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"1325b55c-a171-4684-b421-27f9ad4cd7a1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\n–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫-—Ç–æ —Ç–∞–∫: \\n\\n<IN>–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø—Ä–æ—á—Ç–µ–Ω–∏–µ –°–¢–≠ –Ω–µ –æ—Ç—Ä–∏—Ü–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≠–° –∏ –µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –≤–∏–¥–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –Ω–æ –¥–µ–ª–∞–µ—Ç –∞–∫—Ü–µ–Ω—Ç –Ω–∞ \"–º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–º —Ñ–∞–∫—Ç–æ—Ä–µ\" –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏. –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, –±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ –≤–∞—à –æ—Ç–≤–µ—Ç –ø–æ —Å—É—â–µ—Å—Ç–≤—É. ü§ù\\n<OUT>–í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–π –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –Ω–µ —Å—Ç–æ–ª—å –æ—á–µ–≤–∏–¥–Ω—ã (–æ—Å–æ–±–µ–Ω–Ω–æ —Å —É—á–µ—Ç–æ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä—è–º–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≥–µ–Ω-–ø—Ä–∏–∑–Ω–∞–∫).  –í—Å–µ–≥–¥–∞ –µ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–æ—Ä—Ñ–æ–∑–∞.\\n<END>\\n<IN>–ü—Ä–æ—Å—Ç–æ —Ç–µ–º–∞ —Å–∞–º–∞ —Ä–∏—Ñ–º—É–µ—Ç—Å—è —Å —Å–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–º –≥–æ—Å—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º...\\n<OUT>–Ω—É —á—Ç–æ –≤–∞–º —Ç–∞–∫ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–ª–æ—Å—å... –≤—Å–µ–º —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–∞–º –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–æ—á–Ω–µ–µ, —Å —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π —Ä–∞–Ω–¥–æ–º. —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –≤–æ—Ç –±—É–¥–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –ø—Ä–æ–µ–∫—Ç ‚Äî —Ç–æ–≥–¥–∞ –∏ –Ω–∞–¥–æ –±—É–¥–µ—Ç –≤—ã–±–∏–≤–∞—Ç—å –¥–ª—è –Ω–µ–≥–æ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ\\n<END>\\n\\n–í –ø—Ä–æ—Å—Ç–æ–º —Ç–µ—Å–∫—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ... —Ç–∏–ø –¥–∞—Ç–∞—Å–µ—Ç–∞ —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ QA –∏–ª–∏ conversation\\n\\n'"]},"metadata":{},"execution_count":1}],"source":["'''\n","\n","–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫-—Ç–æ —Ç–∞–∫: \n","\n","<IN>–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø—Ä–æ—á—Ç–µ–Ω–∏–µ –°–¢–≠ –Ω–µ –æ—Ç—Ä–∏—Ü–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≠–° –∏ –µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –≤–∏–¥–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –Ω–æ –¥–µ–ª–∞–µ—Ç –∞–∫—Ü–µ–Ω—Ç –Ω–∞ \"–º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–º —Ñ–∞–∫—Ç–æ—Ä–µ\" –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏. –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, –±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ –≤–∞—à –æ—Ç–≤–µ—Ç –ø–æ —Å—É—â–µ—Å—Ç–≤—É. ü§ù\n","<OUT>–í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–π –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –Ω–µ —Å—Ç–æ–ª—å –æ—á–µ–≤–∏–¥–Ω—ã (–æ—Å–æ–±–µ–Ω–Ω–æ —Å —É—á–µ—Ç–æ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä—è–º–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≥–µ–Ω-–ø—Ä–∏–∑–Ω–∞–∫).  –í—Å–µ–≥–¥–∞ –µ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–æ—Ä—Ñ–æ–∑–∞.\n","<END>\n","<IN>–ü—Ä–æ—Å—Ç–æ —Ç–µ–º–∞ —Å–∞–º–∞ —Ä–∏—Ñ–º—É–µ—Ç—Å—è —Å —Å–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–º –≥–æ—Å—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º...\n","<OUT>–Ω—É —á—Ç–æ –≤–∞–º —Ç–∞–∫ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–ª–æ—Å—å... –≤—Å–µ–º —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–∞–º –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–æ—á–Ω–µ–µ, —Å —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π —Ä–∞–Ω–¥–æ–º. —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –≤–æ—Ç –±—É–¥–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –ø—Ä–æ–µ–∫—Ç ‚Äî —Ç–æ–≥–¥–∞ –∏ –Ω–∞–¥–æ –±—É–¥–µ—Ç –≤—ã–±–∏–≤–∞—Ç—å –¥–ª—è –Ω–µ–≥–æ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ\n","<END>\n","\n","–í –ø—Ä–æ—Å—Ç–æ–º —Ç–µ—Å–∫—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ...\n","\n","'''"]},{"cell_type":"code","source":["#@title –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ { vertical-output: true }\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","#@markdown **sberbank-ai/rugpt3medium_based_on_gpt2** - –¥–æ–≤–æ–ª—å–Ω–æ \"–∂–∏—Ä–Ω–∞—è\" –º–æ–¥–µ–ª—å, –Ω—É–∂–µ–Ω GPU c –±–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –ø–∞–º—è—Ç–∏ \n","model_name = \"sberbank-ai/rugpt3medium_based_on_gpt2\"\n","#@markdown –µ—Å–ª–∏ –Ω–µ—Ç —Ç–∞–∫–æ–≥–æ, —Ç–æ –º–æ–∂–Ω–æ **sberbank-ai/rugpt3small_based_on_gpt2** –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fsg6HMVWTXg2","executionInfo":{"status":"ok","timestamp":1655554778014,"user_tz":-180,"elapsed":13228,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"9159a599-c989-4ece-ecbf-f5ce88a717f3"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/config.json from cache at E:\\HF_HOME\\transformers\\c73d5ea1365be5d1d2cc9f3ecb5c6afd77fbd85274871869ff81afeb6e5bbfd5.c7f979c8d927f0e43eb584070478140e210e1b8830f862d45e9f3d39eda2ef5d\n","Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3medium_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 2048,\n","  \"n_special\": 0,\n","  \"output_past\": true,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/vocab.json from cache at E:\\HF_HOME\\transformers\\ba89ad6b78f0cfd5099cf0c469a2efcdaf072a33eaf719eb1d9285ab6933a686.b488da21e063aa1d3ff664d686226d61ee451181ff9213f3da996b42d42f384b\n","loading file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/merges.txt from cache at E:\\HF_HOME\\transformers\\647ef91c1bb01f6b164a096f99ff5a7de7f1c429966df9dfbd3bc01ad42c7e5c.db5526f107eff4fd6c62a9a36a55cd29713e2ebbf3ffa34a9dc838d05f93e811\n","loading file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/config.json from cache at E:\\HF_HOME\\transformers\\c73d5ea1365be5d1d2cc9f3ecb5c6afd77fbd85274871869ff81afeb6e5bbfd5.c7f979c8d927f0e43eb584070478140e210e1b8830f862d45e9f3d39eda2ef5d\n","Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3medium_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 2048,\n","  \"n_special\": 0,\n","  \"output_past\": true,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/config.json from cache at E:\\HF_HOME\\transformers\\c73d5ea1365be5d1d2cc9f3ecb5c6afd77fbd85274871869ff81afeb6e5bbfd5.c7f979c8d927f0e43eb584070478140e210e1b8830f862d45e9f3d39eda2ef5d\n","Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3medium_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 2048,\n","  \"n_special\": 0,\n","  \"output_past\": true,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","loading configuration file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/config.json from cache at E:\\HF_HOME\\transformers\\c73d5ea1365be5d1d2cc9f3ecb5c6afd77fbd85274871869ff81afeb6e5bbfd5.c7f979c8d927f0e43eb584070478140e210e1b8830f862d45e9f3d39eda2ef5d\n","Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3medium_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 2048,\n","  \"n_special\": 0,\n","  \"output_past\": true,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/rugpt3medium_based_on_gpt2/resolve/main/pytorch_model.bin from cache at E:\\HF_HOME\\transformers\\43140bb032fa6b1fee6968924e8366eb0eb976e1bee3bc1296a1d7343320eeb9.e1648542462a06165273241aece83a68b3393a4bb2c5ae004fbc7b38fc2b0b72\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3medium_based_on_gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["#@title –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞  { vertical-output: true }\n","#@markdown –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞—à–µ–π —Ä–∞–∑–º–µ—Ç–∫–∏\n","special_tokens_dict = {'additional_special_tokens': ['<IN>','<OUT>','<END>','|PAD|']}\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","model.resize_token_embeddings(len(tokenizer))\n","print(tokenizer.all_special_tokens)\n","tokenizer.pad_token = '|PAD|'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3x3Org9STahG","executionInfo":{"status":"ok","timestamp":1655554792188,"user_tz":-180,"elapsed":923,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"0dae5e78-f3d7-47ed-ec1b-e9c04f135c56"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Assigning ['<IN>', '<OUT>', '<END>', '|PAD|'] to the additional_special_tokens key of the tokenizer\n"]},{"output_type":"stream","name":"stdout","text":["['<|endoftext|>', '<IN>', '<OUT>', '<END>', '|PAD|']\n"]}]},{"cell_type":"code","source":["cd D:\\PROJECTS\\Telegram data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RodnUBlmUWTn","executionInfo":{"status":"ok","timestamp":1655551865177,"user_tz":-180,"elapsed":10,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"b4223ef2-1de8-449f-e78f-a6d2d1b1c5f0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["D:\\PROJECTS\\Telegram data\n"]}]},{"cell_type":"code","source":["#@title –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞  { vertical-output: true }\n","\n","#@markdown —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏, —ç—Ç–æ —É—Å—Ç—Ä–µ–≤—à–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ\n","\n","#@markdown –æ–Ω –¥–∞–µ—Ç —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏ –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç \n","\n","#@markdown –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–π –±–∞—Ç—á.\n","\n","from transformers import TextDataset,DataCollatorForLanguageModeling\n","\n","train_dataset = TextDataset(\n","          tokenizer=tokenizer,\n","          file_path='all.txt',\n","          block_size=128)\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vmyfZ9vTe9u","executionInfo":{"status":"ok","timestamp":1655553192465,"user_tz":-180,"elapsed":246,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"fd7dd2b9-7ead-4123-fa5e-982dcb80257e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["D:\\Conda\\envs\\Work\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","Loading features from cached file cached_lm_GPT2TokenizerFast_128_all.txt [took 0.240 s]\n"]}]},{"cell_type":"code","source":["#@title –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞  { vertical-output: true }\n","#@markdown –≠—Ç–æ –≤—Ä–æ–¥–µ –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±, –Ω–æ –º–Ω–µ –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è...\n","#@markdown –ú–æ–∂–Ω–æ –Ω–µ –∑–∞–ø—É—Å–∫–∞—Ç—å - –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.\n","\n","from datasets import load_dataset\n","\n","#data_files = {'train': 'train.txt', 'test': 'test.txt'}\n","ds = load_dataset('text', data_files = 'all.txt')\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"])\n","\n","tokenized_dataset = ds.map(tokenize_function, batched=True)"],"metadata":{"cellView":"form","id":"IwkhLtqWU1NO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è { vertical-output: true } \n","\n","from transformers import Trainer, TrainingArguments\n","import torch\n","\n","#@markdown –µ—Å–ª–∏ –Ω–µ –ª–µ–∑–µ—Ç –≤ –ø–∞–º—è—Ç—å, –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å **per_device_train_batch_size**\n","training_args = TrainingArguments(\n","    output_dir=\"./AGI-bot\", #The output directory\n","    #evaluation_strategy=\"epoch\",\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=3, # number of training epochs\n","    per_device_train_batch_size= 25, # batch size for training\n","    #per_device_eval_batch_size=50,  # batch size for evaluation\n","    eval_steps = 500, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved \n","    warmup_steps=500,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    )\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    #train_dataset=tokenized_dataset['train'],\n","    train_dataset=train_dataset,\n","    #eval_dataset=test_dataset,\n","    #compute_metrics=compute_metrics,\n",")\n","\n","torch.cuda.empty_cache()"],"metadata":{"id":"5L_OjwsDT8O2","executionInfo":{"status":"ok","timestamp":1655551881401,"user_tz":-180,"elapsed":1356,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#@title –û–±—É—á–µ–Ω–∏–µ { vertical-output: true } \n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":808},"id":"V12NeOqJEFyy","executionInfo":{"status":"ok","timestamp":1654455389368,"user_tz":-180,"elapsed":1695454,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"5934bc4b-ac6a-4096-c95b-5c734d082ef6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["D:\\Conda\\envs\\Work\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 28687\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 24\n","  Total train batch size (w. parallel, distributed & accumulation) = 24\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3588\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3588' max='3588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3588/3588 28:11, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.829200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.496900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.302200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.188900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.116200</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.981500</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>2.965200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./AGI-bot\\checkpoint-800\n","Configuration saved in ./AGI-bot\\checkpoint-800\\config.json\n","Model weights saved in ./AGI-bot\\checkpoint-800\\pytorch_model.bin\n","Saving model checkpoint to ./AGI-bot\\checkpoint-1600\n","Configuration saved in ./AGI-bot\\checkpoint-1600\\config.json\n","Model weights saved in ./AGI-bot\\checkpoint-1600\\pytorch_model.bin\n","Saving model checkpoint to ./AGI-bot\\checkpoint-2400\n","Configuration saved in ./AGI-bot\\checkpoint-2400\\config.json\n","Model weights saved in ./AGI-bot\\checkpoint-2400\\pytorch_model.bin\n","Saving model checkpoint to ./AGI-bot\\checkpoint-3200\n","Configuration saved in ./AGI-bot\\checkpoint-3200\\config.json\n","Model weights saved in ./AGI-bot\\checkpoint-3200\\pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3588, training_loss=3.2611268042454884, metrics={'train_runtime': 1695.4189, 'train_samples_per_second': 50.761, 'train_steps_per_second': 2.116, 'total_flos': 1.998122761794355e+16, 'train_loss': 3.2611268042454884, 'epoch': 3.0})"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#@title —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã { vertical-output: true }\n","T_OUT = tokenizer.encode('<OUT>')[0]\n","T_END = tokenizer.encode('<END>')[0]\n","T_PAD = tokenizer.encode('|PAD|')[0]\n","\n","T_OUT, T_END, T_PAD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqKIycDKwWk1","executionInfo":{"status":"ok","timestamp":1655555229993,"user_tz":-180,"elapsed":16,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"861fefb9-ecd1-4766-ae20-efe800507f0c"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50259, 50260, 50261)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["#@title –ò–Ω—Ñ–µ—Ä–µ–Ω—Å (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ) { vertical-output: true }\n","#@markdown –∫–∞–≤—ã—á–∫–∏ –Ω–µ —É–±–∏—Ä–∞—Ç—å!!!\n","text = \"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π –∂–µ–ª–µ–∑—è–∫–∞ —Ä–∞–∑—É–º–Ω–∞—è! –ö–∞–∫ —É —Ç–µ–±—è —Å–µ–≥–æ–¥–Ω—è –¥–µ–ª–∞?\" #@param {type:\"raw\"}\n","model.cuda()\n","\n","text = f\"<IN>{text}\\n<OUT>\"\n","inpt = tokenizer.encode(text, return_tensors=\"pt\")\n","inpt= inpt.cuda()\n","\n","out = model.generate(inpt,  max_length=len(inpt[0])+300, do_sample=True, top_k=5, top_p=0.95, temperature=1, eos_token_id=T_END, pad_token_id=T_PAD)\n","\n","out_tokens = torch.where(out[0]==T_OUT)\n","last_repl = out[0][out_tokens[0][-1]+1:-1]\n","repl = tokenizer.decode(last_repl)\n","\n","print(repl)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TEjbCJbPIun","executionInfo":{"status":"ok","timestamp":1655555263967,"user_tz":-180,"elapsed":468,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"ff901274-14f3-40c4-ae5f-47661e907008","cellView":"form"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["–î–∞ –≤–æ—Ç, —Ä–µ—à–∏–ª —Å —É—Ç—Ä–∞ –ø–æ—Ä–∞–Ω—å—à–µ –∑–∞–Ω—è—Ç—å—Å—è —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ–º.\n","\n"]}]},{"cell_type":"code","source":["# —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏. –í —Ç–∞–∫–æ–º –≤–∏–¥–µ –µ–µ –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ huggingface\n","#@title –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä { vertical-output: true } \n","\n","#@markdown –≤ —Ç–∞–∫–æ–º –≤–∏–¥–µ —É–∂–µ –º–æ–∂–Ω–æ –∑–∞–∫–∏–Ω—É—Ç—å –Ω–∞ https://huggingface.co/\n","#@markdown ,–Ω–æ —ç—Ç–æ —É–∂–µ –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç–µ–º–∞ –∏ –Ω–µ –≤ –±–ª–æ–∫–Ω–æ—Ç–µ \n","\n","model.save_pretrained('AGIRussia')\n","tokenizer.save_pretrained('AGIRussia')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6q8gonrmWycC","executionInfo":{"status":"ok","timestamp":1655554249265,"user_tz":-180,"elapsed":4069,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"d5c7566e-d1f4-4fe2-8228-815c4dfeec42"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in AGIRussia\\config.json\n","Model weights saved in AGIRussia\\pytorch_model.bin\n","tokenizer config file saved in AGIRussia\\tokenizer_config.json\n","Special tokens file saved in AGIRussia\\special_tokens_map.json\n"]},{"output_type":"execute_result","data":{"text/plain":["('AGIRussia\\\\tokenizer_config.json',\n"," 'AGIRussia\\\\special_tokens_map.json',\n"," 'AGIRussia\\\\vocab.json',\n"," 'AGIRussia\\\\merges.txt',\n"," 'AGIRussia\\\\added_tokens.json',\n"," 'AGIRussia\\\\tokenizer.json')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#@title –ê –≤–æ—Ç —Ç–∞–∫ –ø–æ—Ç–æ–º —Å huggingface –¥–æ—Å—Ç–∞–µ–º –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º { vertical-output: true } \n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","model_name = \"Nehc/AGIRussia\" #\"models\\AGIRussia\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdeeESqrtJYF","executionInfo":{"status":"ok","timestamp":1655555151362,"user_tz":-180,"elapsed":11560,"user":{"displayName":"Dim Nst","userId":"16751574260776065634"}},"outputId":"55d7496e-0058-4a88-d113-a96eb6afcdbc"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/Nehc/AGIRussia/resolve/main/vocab.json from cache at E:\\HF_HOME\\transformers\\6830227586c746675d384959b1d44c547d38042e6276857d01a41fbb241e80b5.b488da21e063aa1d3ff664d686226d61ee451181ff9213f3da996b42d42f384b\n","loading file https://huggingface.co/Nehc/AGIRussia/resolve/main/merges.txt from cache at E:\\HF_HOME\\transformers\\8e8ebfbf1549d9b778ce404310b754fab1aa6a0a9b1f6881fb2321d13b5fe081.db5526f107eff4fd6c62a9a36a55cd29713e2ebbf3ffa34a9dc838d05f93e811\n","loading file https://huggingface.co/Nehc/AGIRussia/resolve/main/tokenizer.json from cache at E:\\HF_HOME\\transformers\\1af74ec5a2982000dc0f016692ffcdba3d1ab47a8fc3562a4c2ae95609966cef.af72d954e5ea573a8215b12e8a8b37788a01cedbc7682b377a3bef123ea3ba33\n","loading file https://huggingface.co/Nehc/AGIRussia/resolve/main/added_tokens.json from cache at E:\\HF_HOME\\transformers\\941aae9037065c7692ec4bfcfc42d6af925be53e9c48dd0e064663b7ba2a0ece.4ee0ab48916932a0b9c86a3fb9bea5a7179927323c5e6e72b8d7e37815b30935\n","loading file https://huggingface.co/Nehc/AGIRussia/resolve/main/special_tokens_map.json from cache at E:\\HF_HOME\\transformers\\cea521cd3caf8c9794c3c98a82401bf7b91ed888637f6d35519f33d9e3da7810.0cfad2f793858830728da8a757cc87ecfcc3e6157591e58414e61b43abfbbd4d\n","loading file https://huggingface.co/Nehc/AGIRussia/resolve/main/tokenizer_config.json from cache at E:\\HF_HOME\\transformers\\c9a3701e06afefaa89d1bfb622974877a892323e7f6fbf674bd9e0319e6e2a93.bf10e26a7ed1e23870451199390ff72b6dd1c7ff8554d1d3bbc999c0805a2a18\n","loading configuration file https://huggingface.co/Nehc/AGIRussia/resolve/main/config.json from cache at E:\\HF_HOME\\transformers\\f2e738efc09e5f7c2b9585d889617108db1e1d004b10dc7f0833c54474ce3afe.be1250a578304d7d86ffd958c6cf06ad45e96dd0f09d38c4f8ea2ef17021ad47\n","Model config GPT2Config {\n","  \"_name_or_path\": \"Nehc/AGIRussia\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 2048,\n","  \"n_special\": 0,\n","  \"output_past\": true,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50262\n","}\n","\n","loading weights file https://huggingface.co/Nehc/AGIRussia/resolve/main/pytorch_model.bin from cache at E:\\HF_HOME\\transformers\\390eebcc88ce91ad25df7ed85785aab267b136d934095d2be286eec1fe58e1e7.c5124d726514eae9836b368705d3d7cdc3331444e408e4ff2b8067f03d899ece\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at Nehc/AGIRussia.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]}]}]}